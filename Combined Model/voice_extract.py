# -*- coding: utf-8 -*-
"""voice_extract.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1460LhVSlgaque3lj5PDPW385eeWihsSI
"""

#!pip install praat-parselmouth numpy pandas
#!pip install -q pydub
#!sudo apt-get update -y
#!sudo apt-get install -y libportaudio2 libportaudio-dev ffmpeg

# Install dependencies


# Imports
import parselmouth
import numpy as np
import pandas as pd

def extract_full_parkinsons_features(audio_path, name="sample"):
    snd = parselmouth.Sound(audio_path)

    pitch = snd.to_pitch()
    fo = parselmouth.praat.call(pitch, "Get mean", 0, 0, "Hertz")
    fhi = parselmouth.praat.call(pitch, "Get maximum", 0, 0, "Hertz")
    flo = parselmouth.praat.call(pitch, "Get minimum", 0, 0, "Hertz")

    point_process = parselmouth.praat.call(snd, "To PointProcess (periodic, cc)", 75, 500)
    jitter_percent = parselmouth.praat.call(point_process, "Get jitter (local)", 0, 0, 0.0001, 0.02, 1.3)
    jitter_abs = parselmouth.praat.call(point_process, "Get jitter (local, absolute)", 0, 0, 0.0001, 0.02, 1.3)
    rap = parselmouth.praat.call(point_process, "Get jitter (rap)", 0, 0, 0.0001, 0.02, 1.3)
    ppq = parselmouth.praat.call(point_process, "Get jitter (ppq5)", 0, 0, 0.0001, 0.02, 1.3)
    ddp = parselmouth.praat.call(point_process, "Get jitter (ddp)", 0, 0, 0.0001, 0.02, 1.3)

    shimmer = parselmouth.praat.call([snd, point_process], "Get shimmer (local)", 0, 0, 0.0001, 0.02, 1.3, 1.6)
    shimmer_db = parselmouth.praat.call([snd, point_process], "Get shimmer (local_dB)", 0, 0, 0.0001, 0.02, 1.3, 1.6)
    apq3 = parselmouth.praat.call([snd, point_process], "Get shimmer (apq3)", 0, 0, 0.0001, 0.02, 1.3, 1.6)
    apq5 = parselmouth.praat.call([snd, point_process], "Get shimmer (apq5)", 0, 0, 0.0001, 0.02, 1.3, 1.6)
    apq = parselmouth.praat.call([snd, point_process], "Get shimmer (apq11)", 0, 0, 0.0001, 0.02, 1.3, 1.6)
    dda = parselmouth.praat.call([snd, point_process], "Get shimmer (dda)", 0, 0, 0.0001, 0.02, 1.3, 1.6)

    harmonicity = parselmouth.praat.call(snd, "To Harmonicity (cc)", 0.01, 75, 0.1, 1.0)
    hnr = parselmouth.praat.call(harmonicity, "Get mean", 0, 0)
    nhr = 1 / (hnr + 1e-9)

    rpde = 0.5
    dfa = 0.5
    spread1 = -4.0
    spread2 = 0.3
    d2 = 2.0
    ppe = 0.25

    features = {
        "name": name,
        "MDVP:Fo(Hz)": fo,
        "MDVP:Fhi(Hz)": fhi,
        "MDVP:Flo(Hz)": flo,
        "MDVP:Jitter(%)": jitter_percent,
        "MDVP:Jitter(Abs)": jitter_abs,
        "MDVP:RAP": rap,
        "MDVP:PPQ": ppq,
        "Jitter:DDP": ddp,
        "MDVP:Shimmer": shimmer,
        "MDVP:Shimmer(dB)": shimmer_db,
        "Shimmer:APQ3": apq3,
        "Shimmer:APQ5": apq5,
        "MDVP:APQ": apq,
        "Shimmer:DDA": dda,
        "NHR": nhr,
        "HNR": hnr,
        "RPDE": rpde,
        "DFA": dfa,
        "spread1": spread1,
        "spread2": spread2,
        "D2": d2,
        "PPE": ppe,
        "status": 1
    }

    return pd.DataFrame([features])

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
import tensorflow as tf
from tensorflow.keras import layers, models
import librosa
import os
from tqdm import tqdm
import random
import matplotlib.pyplot as plt

# Load dataset
df = pd.read_csv('Park.csv')
X = df.drop(columns=['name', 'status'])
y = df['status']

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y)

# Reshape for CNN (Conv1D expects 3D input)
X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Build CNN model
model = models.Sequential([
    layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),
    layers.BatchNormalization(),
    layers.MaxPooling1D(pool_size=2),
    layers.Dropout(0.3),
    layers.Conv1D(128, kernel_size=3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling1D(pool_size=2),
    layers.Dropout(0.3),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(1, activation='sigmoid')
])

# Compile model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train model
history = model.fit(X_train_cnn, y_train, epochs=80, batch_size=32,
                    validation_split=0.2, verbose=1)

# Predict on test data
y_probs = model.predict(X_test_cnn).flatten()

# Threshold for Parkinson's detection
threshold = 0.3
y_pred = (y_probs > threshold).astype("int32")

# Evaluate model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
auc = roc_auc_score(y_test, y_probs)

print(f"Test Accuracy: {accuracy:.4f}")

# Audio feature extraction function
def extract_features(file_path):
    try:
        y, sr = librosa.load(file_path, sr=None)
        features = {}
        f0 = librosa.yin(y, fmin=80, fmax=400, sr=sr)
        valid_f0 = f0[f0 > 0]
        if len(valid_f0) > 0:
            features['MDVP:Fo(Hz)'] = np.mean(valid_f0)
            features['MDVP:Fhi(Hz)'] = np.max(valid_f0)
            features['MDVP:Flo(Hz)'] = np.min(valid_f0)
            diffs = np.abs(np.diff(valid_f0))
            features['MDVP:Jitter(Abs)'] = np.mean(diffs)
            features['MDVP:Jitter(%)'] = (features['MDVP:Jitter(Abs)'] / features['MDVP:Fo(Hz)']) * 100
            features['MDVP:RAP'] = features['MDVP:Jitter(%)'] * 0.5
            features['MDVP:PPQ'] = features['MDVP:Jitter(%)'] * 0.6
            features['Jitter:DDP'] = features['MDVP:RAP'] * 3
        else:
            return None

        S = np.abs(librosa.stft(y))
        spectral_centroid = np.mean(librosa.feature.spectral_centroid(S=S))
        features['MDVP:Shimmer'] = spectral_centroid
        features['MDVP:Shimmer(dB)'] = 20 * np.log10(spectral_centroid + 1e-9)
        harmonic = librosa.effects.harmonic(y)
        percussive = librosa.effects.percussive(y)
        features['HNR'] = np.mean(harmonic) / (np.mean(percussive) + 1e-9)
        features['NHR'] = 1 / (features['HNR'] + 1e-9)

        # Randomized placeholders for other features
        features['RPDE'] = np.random.uniform(0.3, 0.6)
        features['DFA'] = np.random.uniform(0.6, 0.9)
        features['spread1'] = np.random.uniform(-6, -4)
        features['spread2'] = np.random.uniform(0.1, 0.4)
        features['D2'] = np.random.uniform(1.5, 3.0)
        features['PPE'] = np.random.uniform(0.1, 0.3)

        return features

    except Exception as e:
        print(f"Error processing {file_path}: {str(e)}")
        return None

# Predict Parkinson’s from audio files
def predict_audio_files(model, scaler, threshold=0.3):
    results = []
    for prefix in ['pdtest']:
        for i in tqdm(range(1, 41), desc=f"Processing {prefix} files"):
            file_path = f"{prefix}{i}.wav"
            if not os.path.exists(file_path):
                continue
            features = extract_features(file_path)
            if features is None:
                continue

            expected_columns = ['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)', 'MDVP:Jitter(Abs)',
                                'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP', 'MDVP:Shimmer', 'MDVP:Shimmer(dB)',
                                'Shimmer:APQ3', 'Shimmer:APQ5', 'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR',
                                'RPDE', 'DFA', 'spread1', 'spread2', 'D2', 'PPE']

            row = {col: features.get(col, 0) for col in expected_columns}
            df_feat = pd.DataFrame([row])

            X = scaler.transform(df_feat)
            X_cnn = X.reshape(1, X.shape[1], 1)

            probability = model.predict(X_cnn, verbose=0)[0][0]

            results.append({
                'file': file_path,
                'prediction': "Parkinson's" if probability > threshold else "Healthy",
                'probability': probability
            })

    return pd.DataFrame(results)

# Run audio prediction
results_df = predict_audio_files(model, scaler, threshold=threshold)
print(results_df)

import joblib
model.save('cnn_model.h5')
joblib.dump(scaler, 'scaler.pkl')

from pydub import AudioSegment

for i in range(1, 20):
    if not os.path.exists(f"Recording{i}.m4a"):
                continue
    input_file = f"Recording{i}.m4a"
    output_file = f"test_audio{i}.wav"

    # Load and convert
    audio = AudioSegment.from_file(input_file, format="m4a")
    audio.export(output_file, format="wav")

    print(f"Converted: {input_file} → {output_file}")

def predict_audio_files(model, scaler):
    results = []
    for prefix in ["test_audio"]:
        for i in tqdm(range(1,41), desc=f"Processing {prefix} files"):
            file_path = f"{prefix}{i}.wav"
            if not os.path.exists(file_path):
                continue
            features = extract_features(file_path)
            if features is None:
                continue
            expected_columns = ['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',
                                'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP', 'MDVP:Shimmer',
                                'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5', 'MDVP:APQ',
                                'Shimmer:DDA','NHR', 'HNR', 'RPDE', 'DFA', 'spread1', 'spread2', 'D2', 'PPE']
            row = {col: features.get(col, 0) for col in expected_columns}
            df = pd.DataFrame([row])
            X = scaler.transform(df)
            X_cnn = X.reshape(1, X.shape[1], 1)
            prediction = model.predict(X_cnn, verbose=0)
            probability = prediction[0][0]
            results.append({
                'file': file_path,
                'prediction': "Parkinson's" if probability > 0.3 else "Healthy",
                'probability': probability
            })
    return pd.DataFrame(results)

results_df = predict_audio_files(model, scaler)
results_df.to_csv('all_predictions.csv', index=False)
'''prediction_accuracy = (results_df['prediction'] == "Parkinson's").mean()
name=""
if prediction_accuracy<0.5:
  prediction_accuracy=1.0-prediction_accuracy
  name="Normal"
else:
  name="Parkinsons"
print(f"\nPercentage of {name} patients: {prediction_accuracy:.2%}")
print(results_df[['file', 'prediction', 'probability']])
'''
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score

print(f"Accuracy:  {accuracy_score(y_test, y_pred):.4f}")
print(f"Precision: {precision_score(y_test, y_pred):.4f}")
print(f"Recall:    {recall_score(y_test, y_pred):.4f}")
print(f"F1 Score:  {f1_score(y_test, y_pred):.4f}")
print("Confusion Matrix: ")
print(confusion_matrix(y_test, y_pred))
print(f"ROC AUC:   {roc_auc_score(y_test, y_probs):.4f}")


import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot with seaborn heatmap
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
